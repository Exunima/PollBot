import json
import re
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline

# –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
model_path = "F:/BOT_TELEGRAM/PollBot/Mistral-7B"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ 4-bit –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype="float16"
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map="auto",
    quantization_config=bnb_config,
    trust_remote_code=True
).to(device)

generator = pipeline("text-generation", model=model, tokenizer=tokenizer)
print("‚úÖ Mistral-7B –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")


def extract_json(text):
    text = text.strip()
    text = re.sub(r"```json", "", text)
    text = re.sub(r"```", "", text)

    # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –±–ª–æ–∫–æ–≤ JSON –ø–æ —Å–∫–æ–±–∫–∞–º
    results = []
    brace_stack = []
    start_idx = None

    for i, char in enumerate(text):
        if char == '{':
            if start_idx is None:
                start_idx = i
            brace_stack.append('{')
        elif char == '}':
            if brace_stack:
                brace_stack.pop()
                if not brace_stack and start_idx is not None:
                    results.append(text[start_idx:i+1].strip())
                    start_idx = None

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞–ª–∏–¥–Ω—ã–π –±–ª–æ–∫ (—Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç)
    return results[-1] if results else None


def clean_json_keys(json_data):
    if isinstance(json_data, dict):
        return {k.strip(): clean_json_keys(v) for k, v in json_data.items()}
    elif isinstance(json_data, list):
        return [clean_json_keys(item) for item in json_data]
    return json_data


def process_text_with_mistral(text: str, prompt_type: str, filename: str = "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"):
    try:
        with open(f"prompts/{prompt_type}_prompt.txt", encoding="utf-8") as f:
            prompt_template = f.read()
    except FileNotFoundError:
        raise ValueError(f"‚ùå –ü—Ä–æ–º—Ç prompts/{prompt_type}_prompt.txt –Ω–µ –Ω–∞–π–¥–µ–Ω")

    safe_text = text.replace("{", "{{").replace("}", "}}")
    prompt = prompt_template.replace("{text}", safe_text)

    result = generator(
        prompt,
        max_new_tokens=1100,
        temperature=0.5,
        top_p=0.95,
        repetition_penalty=1.1,
        do_sample=True
    )[0]["generated_text"]

    print("üîç –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n", result)
    extracted_json = extract_json(result)
    if not extracted_json:
        return {
            "type": prompt_type,
            "title": filename.rsplit(".", 1)[0],
            "questions": []
        }

    try:
        structured_data = json.loads(extracted_json)
        if isinstance(structured_data, list) and len(structured_data) > 0:
            structured_data = structured_data[0]
    except json.JSONDecodeError:
        return {
            "type": prompt_type,
            "title": filename.rsplit(".", 1)[0],
            "questions": []
        }

    structured_data = clean_json_keys(structured_data)
    structured_data.setdefault("type", prompt_type)

    # –ù–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Å—Ç—Ä–æ–∫—É
    title_val = structured_data.get("title")
    if not isinstance(title_val, str) or not title_val.strip():
        structured_data["title"] = filename.rsplit(".", 1)[0]

    structured_data.setdefault("questions", [])
    return structured_data
